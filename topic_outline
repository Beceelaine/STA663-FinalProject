Topic: Infinite Latent Feature Models and the Indian Buffet Process

Outline:
	
Definition of Indian Buffet Process (IBP):

In the Indian buffet process, N customers enter a restaurant one after another. Each customer encounters a buffet 
+consisting of infinitely many dishes arranged in a line. The first customer starts at the left of the buffet and 
+takes a serving from each dish, stopping after a Poisson(α) number of dishes. The ith customer moves along the buffet, 
+sampling dishes in proportion to their popularity, taking dish k with probability mk/i , where mk is the number of 
+previous customers who have sampled that dish. Having reached the end of all previous sampled dishes, the ith customer 
+then tries a Poisson(α/i) number of new dishes.

Steps:

-Start by defining a probability distribution over equivalence classes of binary matrices with a finite number of rows and an unbounded number of columns. This distribution is suitable for use as a prior in probabilistic models that represent objects using a potentially infinite array of features

-Next we see that the Indian Buffet Process is a simple generative process that results in the same distribution (as described in previous step) over equivalence classes because IBP has finite number of objects (people) and infinite number of features (dishes)

-We then define a Gibbs Sampler for models using this concept of IBP

-Further, to illustrate how IBP can be used as a prior in models for unsupervised learning, we derive and test a linear-Gaussian latent feature model in which the features are binary

-We start with a finite realization and then take the infinite limit
